{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programmieraufgaben zur 2. Sonderübung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 2. c), d) & e)\n",
    "In dieser Aufgabe sollen Sie die Performance des Gradientenverfahrens (aus der letzten Sonderübung) mit dem Gauß-Newton Verfahren vergleichen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Die Zielfunktion\n",
    "Implementieren Sie je eine Funktion für den Funktionswert und eine für den Gradienten von NLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r_jac(x):\n",
    "    \"\"\"\n",
    "    Jacobian of the inner function\n",
    "    \"\"\"\n",
    "    \n",
    "    ...\n",
    "    \n",
    "    return r_jac\n",
    "    \n",
    "def h(x):\n",
    "    \"\"\"\n",
    "    Value of Rosenbrock function\n",
    "    \"\"\"\n",
    "    \n",
    "    ...\n",
    "    \n",
    "    return h_val\n",
    "\n",
    "def h_grad(x):\n",
    "    \"\"\"\n",
    "    Gradient of Rosenbrock function\n",
    "    \"\"\"\n",
    "    \n",
    "    ...\n",
    "    \n",
    "    return h_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3d Plot der Zielfunktion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "from matplotlib import cm\n",
    "%matplotlib notebook\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Höhenlinienplot der Zielfunktion\n",
    "Plotten sie mit `plt.contour` die vorgegebenen Höhenlinien der Zielfunktion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "levels = np.hstack((np.arange(0,0.9,0.1),np.arange(1,9,1),np.arange(10,300,20)))\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Das Gradientenverfahren\n",
    "Benutzen Sie hierfür die Implementierung aus der 1. Sonderübung (falls Sie nicht teilgenommen haben, ist die Vorlage hier gegeben)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientDescent(obj_func, grad_func, line_search, x_0, epsilon):\n",
    "\n",
    "    \"\"\" classical gradient descent\n",
    "    \n",
    "    Input\n",
    "    ----------\n",
    "    \n",
    "    obj_fun: callable\n",
    "        Objective function to be mimimized.\n",
    "            Input: ndarray, \n",
    "            Output: float\n",
    "        \n",
    "    grad_fun: callable\n",
    "        Gradient of objective function.\n",
    "            Input: ndarray, \n",
    "            Output: ndarray, \n",
    "    \n",
    "    line_search: callable\n",
    "        Line-search procedure to be used in the algorithm.\n",
    "            Input: x: ndarray\n",
    "                    Starting point of the method.\n",
    "                   d: ndarray\n",
    "                    Starting direction of the method (negative gradient). \n",
    "            Output: float\n",
    "        \n",
    "    x_0: ndarray\n",
    "        Starting point of the method.\n",
    "       \n",
    "    epsilon: float\n",
    "        Tolerance for the termination of the method.\n",
    "        \n",
    "        \n",
    "    Output\n",
    "    -------\n",
    "    \n",
    "    x_crit: ndarray\n",
    "        Approx. of a critical point of the objective function.\n",
    "    \n",
    "    f_crit: float\n",
    "        Objective value at x_opt\n",
    "        \n",
    "    k: int\n",
    "        Number of iterations.\n",
    "        \n",
    "    runtime: float\n",
    "        Runtime of the algorithm.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    start_time = time.time()\n",
    "    k = 0\n",
    "    x = x_0\n",
    "    f_grad = ... # Gradienten von f an x auswerten\n",
    "    d = ... # Suchrichtung ergänzen\n",
    "    while ...: # Abbruchkriterium ergänzen\n",
    "        t = ... # Schrittweite bestimmen\n",
    "        x = ... # Update der aktuellen Iterierten\n",
    "        f_grad = ... # Gradient von f an neuer Iterierter\n",
    "        d = ... # Suchrichtung ergänzen\n",
    "        k += 1\n",
    "    x_crit = ... # Approximation eines kritischen Punktes\n",
    "    f_crit = ... # Zielfunktionswert an der Approximation\n",
    "    runtime = ... # Laufzeit des Verfahrens\n",
    "    return x_crit, f_crit, k, runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schrittweitensteuerung\n",
    "Nutzen Sie die in der letzten Sonderübung implementierte Armijo-Regel (falls Sie nicht teilgenommen haben, befindet sich hier eine Vorlage), passen Sie diese gegebenenfalls so an, dass sie sowohl vom Gradientenverfahren, als auch vom Gauß-Newton Verfahren aufgerufen werden kann."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def armijo(x, d, obj_func, grad_func, sigma, rho, gamma):\n",
    "    \n",
    "    \"\"\" Armijo stepzise rule\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    x: ndarray\n",
    "        Current iterate of the optimization algorithm.\n",
    "        \n",
    "    d: ndarray\n",
    "        Search direction.\n",
    "    \n",
    "    obj_fun: callable\n",
    "        Objective function to be mimimized. Returns a number.\n",
    "        \n",
    "    grad_fun: callable\n",
    "        Gradient of objective function, returns a vector.\n",
    "       \n",
    "    sigma: float\n",
    "        Parameter that determines flatness of damped tangent. (0<sigma<1)\n",
    "    \n",
    "    rho: float\n",
    "        Parameter that determines how fast stepsize is decreaded. (0<rho<1)\n",
    "        \n",
    "    gamma: float\n",
    "        Parameter that determines appropriate starting stepsize.\n",
    "        \n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "    t: float\n",
    "        Armijo stepsize.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    f_value = ... # Funktionswert am Punkt x auswerten\n",
    "    t = ... # Start-Schrittweite (t_0 in Algorithmus 2.4)\n",
    "    x_trial = ... # Schritt in Richtung d mit Schrittweite t\n",
    "    f_trial = ... # Funktionswert am Punkt x_trial\n",
    "    while ...: # Abbruchkriterium ergänzen:\n",
    "        t = ... # Schrittweite updaten\n",
    "        x_trial = ... # Schritt in Richtung d mit neuer Schrittweite t\n",
    "        \n",
    "        f_trial = ... # Funktionswert am neuen Punkt x_trial\n",
    "        \n",
    "    if np.linalg.norm(t*d) < 10**(-14):\n",
    "        t = 10**(-7)\n",
    "        \n",
    "    return t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Das Gauß-Newton-Verfahren\n",
    "Implementieren Sie hier das Gauß-Newton-Verfahren. Orientieren Sie sich hierbei an Algorithmus 2.6 und den Angaben auf S.84 im Buch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussnewton_method(h_val, h_grad, r_jac, x_start, line_search, tol):\n",
    "    \n",
    "    \"\"\" Gauss-Newton-Method\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    h_val: callable\n",
    "        function value of nonlinear least squares problem\n",
    "            Input: x: ndarray\n",
    "            Output h_val: float\n",
    "            \n",
    "    h_grad: callable\n",
    "        gradient of nonlinear least squares problem\n",
    "\n",
    "    r_jac: callable\n",
    "        Jacobian of inner function\n",
    "        \n",
    "    x_start: ndarray\n",
    "        start iterate of the optimization algorithm.\n",
    "        \n",
    "    line_search: callable\n",
    "        Line-search procedure to be used in the algorithm.\n",
    "    \n",
    "    tol: float\n",
    "        tolerance parameter for stopping rule\n",
    "        \n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "    x_crit: ndarray\n",
    "        Approx. of a critical point of the objective function.\n",
    "    \n",
    "    f_crit: float\n",
    "        Objective value at x_crit\n",
    "        \n",
    "    k: int\n",
    "        Number of iterations.\n",
    "        \n",
    "    runtime: float\n",
    "        Runtime of the algorithm.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    ...\n",
    "    \n",
    "    return x_crit, f_crit, k, runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ausführung beider Verfahren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zunächst sollte erneut ein Handle für die Armijo-Regel mit der lambda-Notation und die dafür notwendigen Parameter definiert werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 0.5\n",
    "rho = 0.4\n",
    "gamma = 1\n",
    "armijo_rule = lambda x, d: armijo(x, d, h, h_grad, sigma, rho, gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Führen Sie nun beide Verfahren mit der Startpunkt $x^0 = (2,5)^\\top$ und der Toleranz $\\varepsilon = 10^{-4}$ aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diskutieren Sie die Ergebnisse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
